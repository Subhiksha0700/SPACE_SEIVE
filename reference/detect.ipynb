{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "227dbf7e-d3dd-4ec3-b5b0-ab29d3415fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Applied_Machine_Learning\\Project\\yolov5\n",
      "Current working directory: C:\\Applied_Machine_Learning\\Project\\yolov5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Applied_Machine_Learning\\Project\\Venv\\lib\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "import os\n",
    "\n",
    "# Define the root directory of YOLOv5 (if you are not in it already)\n",
    "%cd C:/Applied_Machine_Learning/Project/yolov5\n",
    "\n",
    "# It's a good practice to verify your current working directory\n",
    "print(\"Current working directory:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cb65f80-ee44-49a5-bdc5-911387c579ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  v7.0-303-gcf8b67b7 Python-3.10.8 torch-2.2.2+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 157 layers, 7015519 parameters, 0 gradients, 15.8 GFLOPs\n"
     ]
    }
   ],
   "source": [
    "from models.experimental import attempt_load\n",
    "from utils.general import check_img_size, non_max_suppression, scale_boxes\n",
    "from utils.torch_utils import select_device\n",
    "from utils.dataloaders import LoadImages\n",
    "from utils.plots import save_one_box\n",
    "import torch\n",
    "\n",
    "# Load the model\n",
    "weights_path = 'C:/Applied_Machine_Learning/Project/yolov5/runs/train/yolov5s_results4/weights/best.pt' # replace with your weights path\n",
    "device = select_device('') # select device ('cpu' or 'cuda:0')\n",
    "model = attempt_load(weights_path)  # If there's a device issue, we'll address it in the next line\n",
    "model.to(device)  # Ensure the model is on the correct device\n",
    "stride = int(model.stride.max())  # model stride\n",
    "imgsz = check_img_size(320, s=stride)  # check image size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c9f8558-0252-479d-9505-9d10e56919c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "def draw_square_box_in_folder(folder_path, box_color=(255, 0, 0), thickness=2, margin=100):\n",
    "    # Get the list of files in the folder\n",
    "    files = os.listdir(folder_path)\n",
    "\n",
    "    # Filter out non-image files\n",
    "    image_files = [file for file in files if file.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "    # Ensure there's only one image file in the folder\n",
    "    if len(image_files) != 1:\n",
    "        print(\"Error: There should be exactly one image file in the folder.\")\n",
    "        return\n",
    "\n",
    "    # Load the image\n",
    "    image_path = os.path.join(folder_path, image_files[0])\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Make a copy of the original image to draw on\n",
    "    image_with_box = image.copy()\n",
    "    \n",
    "    # Get the dimensions of the image\n",
    "    height, width = image.shape[:2]\n",
    "\n",
    "    # Calculate the coordinates for the square box\n",
    "    x1 = margin  # Left edge\n",
    "    y1 = margin  # Top edge\n",
    "    x2 = width - margin  # Right edge\n",
    "    y2 = height - margin  # Bottom edge\n",
    "\n",
    "    # Draw the square box\n",
    "    cv2.rectangle(image_with_box, (x1, y1), (x2, y2), box_color, thickness)\n",
    "\n",
    "    \n",
    "    # Overwrite the original image with the image with the box\n",
    "    cv2.imwrite(image_path, image_with_box)\n",
    "\n",
    "    print(\"Boxed image saved successfully.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "caf0e649-71d7-4bab-8064-cd3891a95a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boxed image saved successfully.\n"
     ]
    }
   ],
   "source": [
    "from utils.dataloaders import LoadImages\n",
    "from utils.general import non_max_suppression, scale_boxes, xyxy2xywh\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "# Load the image\n",
    "source = 'C:/Applied_Machine_Learning/Project/Data/master_data/test/image_00000_2021.jpg'  # replace with your image path\n",
    "dataset = LoadImages(source, img_size=imgsz, stride=stride)\n",
    "\n",
    "# Get names and colors\n",
    "names = model.module.names if hasattr(model, 'module') else model.names\n",
    "colors = [[np.random.randint(0, 255) for _ in range(3)] for _ in names]\n",
    "\n",
    "# Run inference\n",
    "model.eval()\n",
    "# for path, img, im0s, vid_cap in dataset:\n",
    "for path, img, im0s, vid_cap, _ in dataset:\n",
    "    img = torch.from_numpy(img).to(device)\n",
    "    img = img.float()  # uint8 to fp16/32\n",
    "    img /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
    "    if img.ndimension() == 3:\n",
    "        img = img.unsqueeze(0)\n",
    "\n",
    "    # Inference\n",
    "    pred = model(img, augment=False, visualize=False)[0]\n",
    "\n",
    "    # Apply NMS\n",
    "    pred = non_max_suppression(pred, 0.25, 0.45, classes=None, agnostic=False)\n",
    "\n",
    "    # Process detections\n",
    "    for i, det in enumerate(pred):  # detections per image\n",
    "        p, s, im0 = path, '', im0s\n",
    "\n",
    "        s += '%gx%g ' % img.shape[2:]  # print string\n",
    "        gn = torch.tensor(im0.shape)[[1, 0, 1, 0]]  # normalization gain whwh\n",
    "        if len(det):\n",
    "            # Rescale boxes from img_size to im0 size\n",
    "            det[:, :4] = scale_boxes(img.shape[2:], det[:, :4], im0.shape).round()\n",
    "\n",
    "        directory_path = 'C:/Applied_Machine_Learning/Project/detections'\n",
    "        shutil.rmtree(directory_path)\n",
    "        \n",
    "        save_dir = Path(directory_path)  # Update this path\n",
    "        save_dir.mkdir(parents=True, exist_ok=True)  # Make sure the directory exists\n",
    "\n",
    "        # Write results and save the cropped images with padding\n",
    "        for *xyxy, conf, cls in reversed(det):\n",
    "            label = f'{names[int(cls)]} {conf:.2f}'\n",
    "            file_name = save_dir / f\"{label}.jpg\"  # Define the file name\n",
    "            \n",
    "            save_one_box(xyxy, im0, file=file_name, pad=300, save=True)  # Adjust t\n",
    "\n",
    "            draw_square_box_in_folder(directory_path)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Display the image\n",
    "plt.imshow(im0)\n",
    "plt.axis('off')  # Hide axis\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1808b99e-73d9-49fc-baa8-3b9b70c5c97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python detect.py --weights '/Users/nithish/Documents/Academics/Spring 24/AML/project/yolov5/runs/train/yolov5s_results4/weights/best.pt' --img 640 --conf 0.25 --source '/Users/nithish/Documents/Academics/Spring 24/AML/project/data/master_data/test/image_00004_2021.jpg'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a0c41a-04dd-4625-a7dc-94b68411ca86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
